{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson_05_Introduction_to_pandas.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "woIhBlBupowm",
        "bCQYczBFsxN5",
        "qozEt3qdv4Zc",
        "H64LApNI2vKJ",
        "5NajzEqj6Usm",
        "OtV3NQPnAgM5",
        "6hN_9QIlH7ey",
        "F8871OlQNvYW",
        "SJNwnlxMS8fc",
        "X0sKBpdxVMM_",
        "wF256cCCnWVa",
        "wjtwE9KKrF5Z"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "Oid5l5CVmnS0",
        "toc-hr-collapsed": true
      },
      "cell_type": "markdown",
      "source": [
        "## 1 Introduction to Pandas"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "woIhBlBupowm"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.1 Understanding pandas\n"
      ]
    },
    {
      "metadata": {
        "id": "x2ouv1i2r3tu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pandas is a popular Python package for data science, and with good reason: it offers powerful, expressive and flexible data structures that make data manipulation and analysis easy, among many other things.\n",
        "\n",
        "In this lesson, we'll learn:\n",
        "\n",
        "- about the two core pandas types: dataframes and series\n",
        "- how to select data using row and column labels\n",
        "- a variety of methods for exploring data with pandas\n",
        "- how to assign data using various techniques in pandas\n",
        "- how to use boolean indexing with pandas for selection and assignment\n",
        "\n",
        "We'll be working with data set from [Fortune](http://fortune.com/) magazine's [Global 500](https://en.wikipedia.org/wiki/Fortune_Global_500) list 2017, which ranks the top 500 corporations worldwide by revenue. The dataset we'll be using was originally compiled [here](https://data.world/chasewillden/fortune-500-companies-2017), however we have modified the original data set into a more accessible format.\n",
        "\n",
        "<img width=\"400\" src=\"https://drive.google.com/uc?export=view&id=1vWtPGbbxR7Mn2xHg_KMa3MOKSqs05uyE\">\n",
        "\n",
        "\n",
        "The dataset is a CSV file called **f500.csv**. Here is a data dictionary for some of the columns in the CSV:\n",
        "\n",
        "- **company** - The Name of the company.\n",
        "- **rank** - The Global 500 rank for the company.\n",
        "- **revenues** - The company's total revenues for the fiscal year, in millions of dollars (USD).\n",
        "- **revenue_change** - The percentage change in revenue between the current and prior fiscal years.\n",
        "- **profits** - Net income for the fiscal year, in millions of dollars (USD).\n",
        "- **ceo** - The company's Chief Executive Officer.\n",
        "- **industry** - The industry in which the company operates.\n",
        "- **sector** - The sector in which the company operates.\n",
        "- **previous_rank** - The Global 500 rank for the company for the prior year.\n",
        "- **country** - The Country in which the company is headquartered.\n",
        "- **hq_location** - The City and Country, (or City and State for the USA) where the company is headquarted.\n",
        "- **employees** - Total employees (full-time equivalent, if available) at fiscal year-end.\n",
        "\n",
        "\n",
        "The import convention for pandas is:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "```\n",
        "\n",
        "We have already imported pandas and used the [pandas.read_csv()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) function to read the CSV into a pandas object and assign it to the variable name f500. In the next mission we'll learn about **read_csv()**, but for now all you need to know is that it handles reading and parsing most CSV files automatically.\n",
        "\n",
        "Pandas objects have a **.shape** attribute which returns a tuple representing the dimensions of each axis of the object. We'll use that and the Python's **type()** function to inspect the f500 pandas object.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "1. Use Python's **type()** function to assign the type of **f500** to **f500_type.**\n",
        "2. Use the **DataFrame.shape** attribute to assign the shape of **f500** to **f500_shape.**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Hn9JxP26rgAo",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "f500 = pd.read_csv(\"f500.csv\", index_col=0)\n",
        "f500.index.name = None\n",
        "\n",
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bCQYczBFsxN5"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2 Introducing DataFrames\n"
      ]
    },
    {
      "metadata": {
        "id": "hcn2UhRC0tRF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "The code we wrote in the previous screen let us know that our data has 500 rows and 16 columns, and is stored as a [pandas.core.frame.DataFrame object](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame). More commonly referred to as **pandas.DataFrame()** objects, or just **dataframes**, the type is the primary pandas data structure. Dataframes are two dimensional pandas objects.\n",
        "\n",
        "We'll learn about the second pandas data structure, series, later in this lesson, but first, let's look at the anatomy of a dataframe, using a selection of our Fortune 500 data:\n",
        "\n",
        "<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1lUAxPbqauhiMPdWCAM2oPOy0vsmvWtYy\">\n",
        "\n",
        "There are three key things we can observe immediately:\n",
        "\n",
        "- In Red: Just like a 2D ndarray, there are two axes, however each axis of a dataframe has a specific name. The first axis is called **index**, and the second axis is called **columns.**\n",
        "- In Blue: Our axis values have string **labels**, not just numeric locations.\n",
        "- In Green: Our dataframe contains columns with **multiple dtypes**: integer, float, and string.\n",
        "\n",
        "We can use the [DataFrame.dtypes](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dtypes.html#pandas.DataFrame.dtypes) attribute to return information about the types of each column. Let's see what this would return for our selection of data above:\n",
        "\n",
        "```python\n",
        ">>> f500_selection.dtypes\n",
        "\n",
        "    rank          int64\n",
        "    revenues      int64\n",
        "    profits     float64\n",
        "    country      object\n",
        "    dtype: object\n",
        "```\n",
        "\n",
        "We can see three different data types (dtypes), which correspond to what we observed by looking at the data:\n",
        "\n",
        "- int64\n",
        "- float64\n",
        "- object\n",
        "\n",
        "\n",
        "\n",
        "When we import data, pandas will attempt to guess the correct dtype for each column. Generally, pandas does a pretty good job with this, which means we don't need to worry about specifying dtypes every time we start to work with data. Later in this course, we'll look at how to change the dtype of a column.\n",
        "\n",
        "Next, let's learn a few handy methods we can use to get some high-level information about our dataframe:\n",
        "\n",
        "- If we wanted to view the first few rows of our dataframe, we can use the [DataFrame.head()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html) method, which returns the first 5 rows of our dataframe. The **DataFrame.head()** method also accepts an optional integer parameter which specified the number of rows. We could use **f500.head(10)** to return the first 10 rows of our **f500 dataframe**.\n",
        "- Similar in function to **DataFrame.head()**, we can use the [DataFrame.tail()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.tail.html) method, to shows us the last rows of our dataframe. The **DataFrame.tail()** method accepts an optional integer parameter to specify the number of rows, defaulting to 5.\n",
        "- If we wanted to get an overview of all the dtypes used in our dataframe, along with its shape and some extra information, we could use the [DataFrame.info()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html#pandas.DataFrame.info) method. Note that **DataFrame.info()** prints the information, rather than returning it, so we can't assign it to a variable.\n",
        "\n",
        "Let's practice using these three new methods. Just like in the previous missions, the f500 variable we created in the previous section is available to you here.\n",
        "\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "1. Using the links above to the documentation if you need to, use the three methods we just learned about to learn more about the **f500** dataframe:\n",
        "\n",
        "  - Use the **head()** method to select the first 6 rows and assign the result to **f500_head**.\n",
        "  - Use the **tail()** method to select the last 8 rows and assign the result to **f500_tail.**\n",
        "  - Use the **info()** method to display information about the dataframe.\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JW4ZDCUFs0X8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "qozEt3qdv4Zc"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.3 Selecting Columns From a DataFrame by Label\n"
      ]
    },
    {
      "metadata": {
        "id": "yGBWO8oM2oFL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "By looking at the results produced by the **DataFrame.head()** and **DataFrame.tail()** methods in the previous screen, we can see that our data set seems to be pre-sorted in order of Fortune 500 rank.\n",
        "\n",
        "We can also see that the **DataFrame.info()** method showed us the number of entries in our index (representing the number of rows), a list of each column with their dtype and the number of non-null values, as well as a summary of the different dtypes and memory usage. In pandas, null values are represented using NaN.\n",
        "\n",
        "Because our axes in pandas have labels, we can select data using those labels. To do this, we use the [DataFrame.loc[]](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html#pandas.DataFrame.loc) method.\n",
        "\n",
        "Throughout our pandas lessons you'll see **df** used in code examples as shorthand for a dataframe object. We use this convention because you also see this throughout the official pandas documentation, so getting used to reading it is important. You'll notice that we use brackets **([])** instead of parentheses **(())** when selecting by location.  The syntax for the **DataFrame.loc[]** method is:\n",
        "\n",
        "```python\n",
        "df.loc[row, column]\n",
        "```\n",
        "\n",
        "Where **row** and **column** refer to row and column labels respectively, and can be one of:\n",
        "\n",
        "- A single label.\n",
        "- A list or array of labels.\n",
        "- A slice object with labels.\n",
        "- A boolean array.\n",
        "\n",
        "We'll look at boolean arrays later in this mission - for now, we're going to focus on the first three options. We're going to use the same selection of data we used in the previous screen, which is stored using the variable name **f500_selection** to make these examples easier.\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1WNexstd5iVGtj04VxjcnQSqa-UTSETDg\">\n",
        "\n",
        "\n",
        "In each of these examples, we're going to use **:** to specify that we wish to select all rows, so we can focus making selections using column labels only.\n",
        "\n",
        "First, let's select a single column by specifying a single label:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=15V82UWlysJjrA_Eg0b5vKPeMcagBhQCI\">\n",
        "\n",
        "\n",
        "Selecting a single column returns a pandas series. We'll talk about pandas series objects more in the next screen, but for now the important thing is to note that the new series has the same index axis labels as the original dataframe. Let's look at how we can use a list of labels to select specific columns:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1MSj7K1OU_0LwnKACxpYLOTfU71faWb4h\">\n",
        "\n",
        "\n",
        "When we use a list of labels, a dataframe is returned with only the columns specified in our list, in the order specified in our list. Just like when we used a single column label, the new dataframe has the same index axis labels as the original. Lets finish by using a **slice object with labels** to select specific columns.\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1CEtF_oFReD_-6pqheEfEd4nRWgakEgXQ\">\n",
        "\n",
        "Again we get a dataframe object, with all of the columns from the first up until **and including** the last column in our slice. \n",
        "\n",
        "Let's practice using these techniques to select specific columns from our f500 dataframe.\n",
        "\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "1. Select the **industry** column, and assign the result to the variable name **industries**.\n",
        "2. Select the **rank**, **previous_rank** and **years_on_global_500_list** columns, in order, and assign the result to the variable name **previous**.\n",
        "3. Select all columns from **revenues** up to and including **profit_change**, in order, and assign the result to the variable name **financial_data**."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TU2gt3piwuXx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# put your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "H64LApNI2vKJ"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.4 Column selection shortcuts\n"
      ]
    },
    {
      "metadata": {
        "id": "TWYgWMke6m3R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "There are two shortcuts that pandas provides for accessing columns.\n",
        "\n",
        "1. **Single Bracket** – Instead of **df.loc[:,\"col_1\"]** you can use **df[\"col1\"]** to select columns. This works for single columns and lists of columns but not for for column slices. \n",
        "2. **Dot Accessor** – Instead of **df.loc[:,\"col_1\"]** you can use **df.col_1**. This shortcut does not work for labels that contain spaces or special characters. \n",
        "\n",
        "These shortcuts are designed to make some of the more common selection tasks easier. We recommend you always use the common shorthand in your code, as it will make your code easier to read. A summary of the techniques we've learned so far is below:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1BlhNf3XAGs0E50GISg0-W0sZXcRowrRe\">\n",
        "\n",
        "Let's practice selecting data by column some more, this time using the common shorthand method.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "1. Select the **country** column, and assign the result to the variable name **countries**.\n",
        "2. Select the **revenues** and **years_on_global_500_list** columns, in order, and assign the result to the variable name **revenues_years**.\n",
        "3. Select all columns from **ceo** up to and including **sector**, in order, and assign the result to the variable name **ceo_to_sector**.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aR-77Tqb49NM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5NajzEqj6Usm"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.5 Selecting Items from a Series by Label\n"
      ]
    },
    {
      "metadata": {
        "id": "aLLK0RFU7JlT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "In the last section we observed that when you select just one column of a dataframe, you get a new pandas type: a **series object**. Series is the pandas type for one-dimensional objects. Anytime you see a 1D pandas object, it will be a series, and anytime you see a 2D pandas object, it will be a dataframe.\n",
        "\n",
        "You might like to think of a dataframe as being a collection of series objects, which is similar to how pandas stores the data behind the scenes.\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1xNxF1TgmYOzlYj6ogofxKBiSO7FqsHOH\">\n",
        "\n",
        "\n",
        "To better understand the relationship between dataframe and series objects, we'll look at some examples. We'll start by looking at two pandas operations that each produce a series object:\n",
        "\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1aI-saLdbP4eZOQKGjHTJT54mFCa2Vu42\">\n",
        "\n",
        "Because a series has only one axis, its axis labels are either the index axis or column axis labels, depending on whether it is representing a row or a column from the original dataframe. If we make a 2D selection from a dataframe, it will retain the labels from both axes:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1YyiMWxDLQ8bo4vkL1qZc5Pq49C4KNqE8\">\n",
        "\n",
        "Let's look at a brief summary of the differences between dataframes and series'.\n",
        "\n",
        "\n",
        "<img width=\"400\" src=\"https://drive.google.com/uc?export=view&id=1k7GgAAgsHY8YD-Z8x7Enerozt9MlqkuR\">\n",
        "\n",
        "\n",
        "Just like dataframes, we can use **Series.loc[]** to select items from a series using single labels, a list, or a slice object. We can also omit **loc[]** and use bracket shortcuts for all three. Let's look at an example:\n",
        "\n",
        "```python\n",
        ">>> print(s)\n",
        "\n",
        "a    0\n",
        "b    1\n",
        "c    2\n",
        "d    3\n",
        "e    4\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "We can select a single item:\n",
        "\n",
        "```python\n",
        "print(s[\"d\"])\n",
        "\n",
        "3\n",
        "```\n",
        "\n",
        "Like with dataframe columns, there is a dot accessor (eg, **s.d**) available, but this rarely used– even less than the dataframe dot accessor.\n",
        "\n",
        "To select several items using a list:\n",
        "\n",
        "```python\n",
        "print(s[[\"a\", \"e\", \"c\"]])\n",
        "\n",
        "a    0\n",
        "e    4\n",
        "c    2\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "And lastly, several items using a slice:\n",
        "\n",
        "```python\n",
        "print(s[\"a\":\"d\"])\n",
        "\n",
        "a    0\n",
        "b    1\n",
        "c    2\n",
        "d    3\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "Let's practice selecting data from pandas series':\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "1. From the pandas series **ceos**:\n",
        "  -  Select the item at index label **Walmart** and assign the result to the variable name **walmart**.\n",
        "  -  Select the items from index label **Apple** up to and including index label **Samsung Electronics** and assign the result to the variable name **apple_to_samsung**.\n",
        "  -  Select the items with index labels **Exxon Mobil**, **BP**, and **Chevron**, in order, and assign the result to the variable name **oil_companies**.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "u9MZtd2x7KJk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ceos = f500[\"ceo\"]\n",
        "\n",
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "OtV3NQPnAgM5"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.6 Selecting Rows From a DataFrame by Label\n"
      ]
    },
    {
      "metadata": {
        "id": "h4q4Y1I37Plt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now that we've learned how to select columns using the labels of the **'column'** axis, let's learn how to select rows using the labels of the **'index'** axis.\n",
        "\n",
        "<img width=\"400\" src=\"https://drive.google.com/uc?export=view&id=1HH7k0yK6abEG4xKiHgPTt5I_rz1OE5UD\">\n",
        "\n",
        "Selecting **rows** from a dataframe by label uses the same syntax as we use for **columns.** As a reminder:\n",
        "\n",
        "```python\n",
        "df.loc[row, column]\n",
        "```\n",
        "\n",
        "Where **row** and **column** refer to row and column labels. We'll look at how to select rows, again using our **f500_selection** dataframe to make these examples easier.\n",
        "\n",
        "```python\n",
        "print(type(f500_selection)\n",
        "print(f500_selection)\n",
        "```\n",
        "\n",
        "```python\n",
        "class 'pandas.core.frame.DataFrame'\n",
        "\n",
        "                          rank  revenues  profits country\n",
        "Walmart                      1    485873  13643.0     USA\n",
        "State Grid                   2    315199   9571.3   China\n",
        "Sinopec Group                3    267518   1257.9   China\n",
        "China National Petroleum     4    262573   1867.5   China\n",
        "Toyota Motor                 5    254694  16899.3   Japan\n",
        "```\n",
        "\n",
        "To select a single row:\n",
        "\n",
        "```python\n",
        "single_row = f500_selection.loc[\"Sinopec Group\"]\n",
        "print(type(single_row))\n",
        "print(single_row)\n",
        "\n",
        "class 'pandas.core.series.Series'\n",
        "\n",
        "rank             3\n",
        "revenues    267518\n",
        "profits     1257.9\n",
        "country      China\n",
        "Name: Sinopec Group, dtype: object\n",
        "```\n",
        "\n",
        "As we would expect, a single row is returned as a series. We should take a moment to note that the dtype of this series is object. Because this series has to store integer, float, and string values pandas uses the object dtype, since none of the numeric types could cater for all values.\n",
        "\n",
        "To select a list of rows:\n",
        "\n",
        "```python\n",
        "list_rows = f500_selection.loc[[\"Toyota Motor\", \"Walmart\"]]\n",
        "print(type(list_rows))\n",
        "print(list_rows)\n",
        "\n",
        "class 'pandas.core.frame.DataFrame'\n",
        "\n",
        "              rank  revenues  profits country\n",
        "Toyota Motor     5    254694  16899.3   Japan\n",
        "Walmart          1    485873  13643.0     USA\n",
        "```\n",
        "\n",
        "For selection using slices, we can use the shortcut without brackets. This is the reason we can't use this shortcut for columns - because it's reserved for use with rows:\n",
        "\n",
        "```python\n",
        "slice_rows = f500_selection[\"State Grid\":\"Toyota Motor\"]\n",
        "print(type(slice_rows))\n",
        "print(slice_rows)\n",
        "```\n",
        "\n",
        "```python\n",
        "class 'pandas.core.frame.DataFrame'\n",
        "\n",
        "                          rank  revenues  profits country\n",
        "State Grid                   2    315199   9571.3   China\n",
        "Sinopec Group                3    267518   1257.9   China\n",
        "China National Petroleum     4    262573   1867.5   China\n",
        "Toyota Motor                 5    254694  16899.3   Japan\n",
        "```\n",
        "\n",
        "Let's take a look at a summary of all the different label selection methods we've learned so far:\n",
        "\n",
        "\n",
        "<img width=\"800\" src=\"https://drive.google.com/uc?export=view&id=1rQMPkOZBVh57x6kVu5qWjU3UC6vCh9v_\">\n",
        "\n",
        "\n",
        "Now for some practice - we're going to make it a little bit harder this time, by asking you to combine selection methods for rows and columns on both dataframes and series!\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "1. By selecting data from **f500**:\n",
        "  - Create a new variable, **drink_companies**, with:\n",
        "    - Rows with indicies **Anheuser-Busch InBev**, **Coca-Cola**, and **Heineken Holding**, in that order.\n",
        "     - All columns.\n",
        "  - Create a new variable **big_movers**, with:\n",
        "    - Rows with indicies **Aviva**, **HP**, **JD.com**, and **BHP Billiton**, in that order.\n",
        "    - The **rank** and **previous_rank** columns, in that order.\n",
        "  - Create a new variable, **middle_companies** with:\n",
        "    - All rows with indicies from **Tata Motors** to **Nationwide**, inclusive.\n",
        "    - All columns from **rank** to **country**, inclusive."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yrqIppYaB60O",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6hN_9QIlH7ey"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.7 Series and Dataframe Describe Methods\n"
      ]
    },
    {
      "metadata": {
        "id": "eaBTv4_57ng8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "We're starting to get a feel for how axes labels in pandas make selecting data much easier. Pandas also has a large number of methods and functions that make working with data easier. Let's use a few of these to explore our Fortune 500 data.\n",
        "\n",
        "The first method we'll learn about is the [Series.describe()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.describe.html#pandas.Series.describe) method, which returns some descriptive statistics on the data contained within a specific pandas series. Let's look at an example:\n",
        "\n",
        "```python\n",
        "revs = f500[\"revenues\"]\n",
        "print(revs.describe())\n",
        "```\n",
        "\n",
        "```python\n",
        "count       500.000000\n",
        "mean      55416.358000\n",
        "std       45725.478963\n",
        "min       21609.000000\n",
        "25%       29003.000000\n",
        "50%       40236.000000\n",
        "75%       63926.750000\n",
        "max      485873.000000\n",
        "Name: revenues, dtype: float64\n",
        "```\n",
        "\n",
        "We've assigned the **revenues** column to a new series, **revs**, and then used the **describe()** method on that series. The method tells us how many non-null values are contained in the series, the mean and standard devation, along with the minimum, maximum and [quartile](https://en.wikipedia.org/wiki/Quartile) values.\n",
        "\n",
        "Rather than assigning the series to it's own variable, we can actually skip that step and use the method directly on the result of the column selection. This is called **method chaining** and is a way to combine multiple methods together in a single line. It's not unique to pandas, however it is something that you see a lot in pandas code. Let's see what the command looks like with method chaining, using the **assets** column.\n",
        "\n",
        "\n",
        "```python\n",
        "print(f500[\"assets\"].describe())\n",
        "```\n",
        "\n",
        "```python\n",
        "count    5.000000e+02\n",
        "mean     2.436323e+05\n",
        "std      4.851937e+05\n",
        "min      3.717000e+03\n",
        "25%      3.658850e+04\n",
        "50%      7.326150e+04\n",
        "75%      1.805640e+05\n",
        "max      3.473238e+06\n",
        "Name: assets, dtype: float64\n",
        "```\n",
        "\n",
        "From here, you'll start to see method chaining used more in our missions. When writing code, you should always assess whether method chaining will make your code harder to read. It's always preferable to break out into more than one line if it will make your code easier to understand.\n",
        "\n",
        "You might have noticed that the values in the code segment above look a little bit different. Because the values for this column are too long to display neatly, pandas has displayed them in **E-notation**, a type of [scientific notation](https://en.wikipedia.org/wiki/Scientific_notation). Here is an expansion of what the E-notation represents:\n",
        "\n",
        "| Original Notation | Expanded Formula | Result |\n",
        "|-------------------|--------------------|----------|\n",
        "| 5.000000E+02 | 5.000000 * 10 ** 2 | 500 |\n",
        "| 2.436323E+05 | 2.436323 * 10 ** 5 | 243632.3 |\n",
        "\n",
        "\n",
        "If we use **describe()** on a column that contains non-numeric values, we get some different statistics. Let's look at an example:\n",
        "\n",
        "```python\n",
        "print(f500[\"country\"].describe())\n",
        "\n",
        "count     500\n",
        "unique     34\n",
        "top       USA\n",
        "freq      132\n",
        "Name: country, dtype: object\n",
        "```\n",
        "\n",
        "Here is what the output indicates:\n",
        "\n",
        "The first statistic, **count**, is the same as for numeric columns, showing us the number of non-null values. The other three statistics are new:\n",
        "\n",
        "- **unique** - The number of unique values in the series. In this case, it tells us that there are 34 different countries represented in the Fortune 500.\n",
        "- **top** - The most common value in the series. The USA is the most common country that a company in the Fortune 500 is headquartered in.\n",
        "- **freq** - The frequency of the most common value. The USA is the country that 132 companies from Fortune 500 are headquartered in.\n",
        "\n",
        "Because series' and dataframes are two distinct objects, they have their own unique methods. There are many times where both series and dataframe objects have a method of the same name that behaves in similar ways. DataFrame objects also have a [DataFrame.describe()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html) method that returns these same statistics for every column. If you like, you can take a look at the documentation using the link in the previous sentence to familiarize yourself with some of the differences between the two methods.\n",
        "\n",
        "One difference is that you need to specify manually if you want to see the statistics for the non-numeric columns. By default, **DataFrame.describe()** will return statistics for only numeric columns. If we wanted to get just the object columns, we need to use the **include=['O']** parameter when using the dataframe version of describe:\n",
        "\n",
        "```python\n",
        "print(f500.describe(include=['O']))\n",
        "```\n",
        "\n",
        "```python\n",
        "_            ceo    industry     sector  country  hq_location    website\n",
        "count        500         500        500      500          500        500\n",
        "unique       500          58         21       34          235        500\n",
        "top     Xavie...   Banks:...  Financ...      USA  Beijing,...  http:/...\n",
        "freq           1          51        118      132           56          1\n",
        "```\n",
        "\n",
        "Another difference is that **Series.describe()** returns a series object, where **DataFrame.describe()** returns a dataframe object. \n",
        "\n",
        "Let's practice using both the series and dataframe describe methods:\n",
        "\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "1. Use the appropriate **describe()** method to:\n",
        "  - Return a series of descriptive statistics for the **profits** column, and assign the result to **profits_desc**.\n",
        "  - Return a dataframe of descriptive statistics for the **revenues** and **employees** columns, in order, and assign the result to **revenue_and_employees_desc**.\n",
        "  - Return a dataframe of descriptive statistics for every column in the **f500** dataframe, by checking the documentation for the correct value for the **include** parameter, and assign the result to **all_desc**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "h43tBXdoKpnl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "F8871OlQNvYW"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.8 More Data Exploration Methods\n"
      ]
    },
    {
      "metadata": {
        "id": "P5yeuEv877Bv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "One basic concept in Pandas are the vectorized operations. Let's look at an example of how this would work with a pandas series:\n",
        "\n",
        "```python\n",
        ">>> print(my_series)\n",
        "\n",
        "    0    1\n",
        "    1    2\n",
        "    2    3\n",
        "    3    4\n",
        "    4    5\n",
        "    dtype: int64\n",
        "\n",
        ">>> my_series = my_series + 10\n",
        "\n",
        ">>> print(my_series)\n",
        "\n",
        "    0    11\n",
        "    1    12\n",
        "    2    13\n",
        "    3    14\n",
        "    4    15\n",
        "    dtype: int64\n",
        "```\n",
        "\n",
        "Many of the descriptive stats methods are also supported. Here are a few handy methods (with links to documentation) that you might use when working with data in pandas:\n",
        "\n",
        "- [Series.max()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.max.html) and [DataFrame.max()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.max.html)\n",
        "- [Series.min()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.min.html) and [DataFrame.min()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.min.html)\n",
        "- [Series.mean()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.mean.html) and [DataFrame.mean()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.mean.html)\n",
        "- [Series.median()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.median.html) and [DataFrame.median()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.median.html)\n",
        "- [Series.mode()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.mode.html) and [DataFrame.mode()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.mode.html)\n",
        "- [Series.sum()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.sum.html) and [DataFrame.sum()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sum.html)\n",
        "\n",
        "\n",
        "As the documentation indicates, the series methods don't require an axis parameter, however the dataframe methods will so we know which axis to calculate across. While you can use integers to refer to the first and second axis, pandas dataframe methods also accept the strings **\"index\"** and **\"columns\"** for the axis parameter. Let's refresh our memory on how this works:\n",
        "\n",
        "<img width=\"700\" src=\"https://drive.google.com/uc?export=view&id=1euiSMOgXE7IVP_U-VIRzwV6JAXBpC4yx\">\n",
        "\n",
        "For instance, if we wanted to find the median (middle) value for the **revenues** and **profits** columns, we could use the following code:\n",
        "\n",
        "```python\n",
        "medians = f500[[\"revenues\", \"profits\"]].median(axis=0)\n",
        "# we could also use .median(axis=\"index\")\n",
        "print(medians)\n",
        "\n",
        "revenues    40236.0\n",
        "profits      1761.6\n",
        "dtype: float64\n",
        "  \n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "In fact, the default value for the axis parameter with these methods is **axis=0**, so we could have just used the **median()** method without a parameter to get the same result!\n",
        "\n",
        "Another extremely handy method for exploring data in pandas is the [Series.value_counts()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html) method. The **Series.value_counts()** method displays each unique non-null value from a series, with a count of the number of times that value is used. We saw above that the **sector** column has 21 unique values. Let's use **Series.value_counts()** to look at the top 5:\n",
        "\n",
        "```python\n",
        ">>> print(f500[\"sector\"].value_counts().head())\n",
        "\n",
        "    Financials                118\n",
        "    Energy                     80\n",
        "    Technology                 44\n",
        "    Motor Vehicles & Parts     34\n",
        "    Wholesalers                28\n",
        "    Name: sector, dtype: int64\n",
        "```\n",
        "\n",
        "Let's take a moment to walk through what happened in that line of code:\n",
        "\n",
        "- We used the **print()** function to print the output of the following method chain:\n",
        "    - Select the **sector** column from the **f500** dataframe, and on the resulting series\n",
        "    - Use the **Series.value_counts()** to produce a series of the unique values and their counts in order, and on the resulting series\n",
        "    - Use the [Series.head()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.head.html#pandas.Series.head) method to return the first 5 items only.\n",
        "    \n",
        "    \n",
        "We haven't seen the **Series.head()** method before, but it works similarly to **DataFrame.head()**, returning the first five items from a series, or a different number if you provide an argument.\n",
        "\n",
        "The **Series.value_counts()** method is one of the handiest methods to use when exploring a data set. It's also one of the few series methods that doesn't have a dataframe counterpart.\n",
        "\n",
        "Don't worry too much about having to remember which methods belong to which objects for now. You'll find that as you practice them some will stick, and for the rest you'll be able to reference the pandas documentation.\n",
        "\n",
        "Let's start the process by practicing some of these to explore the Fortune 500 some more!\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "- Use **Series.value_counts()** and **Series.head()** to return the 5 most common values for the **country** column, and assign the results to **top5_countries.**\n",
        "- Use **Series.value_counts()** and **Series.head()** to return the 5 most common values for the **previous rank** column, and assign the results to **top5_previous_rank**.\n",
        "- Use the appropriate **max()** method to find the maximum value for only the numeric columns from **f500** (you may need to check the documentation), and assign the result to the variable **max_f500**.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "H3PtJ5_lOIO5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SJNwnlxMS8fc"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.9 Assignment with pandas\n"
      ]
    },
    {
      "metadata": {
        "id": "ZbtBSYW58rM6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Looking at the results of the most common values for the **previous_rank** column in the last exercise, you might have noticed something a little odd:\n",
        "\n",
        "```python\n",
        ">>> print(top5_previous_rank.head())\n",
        "\n",
        "    0      33\n",
        "    159     1\n",
        "    147     1\n",
        "    148     1\n",
        "    149     1\n",
        "    Name: previous_rank, dtype: int64\n",
        "```\n",
        "\n",
        "This indicates that 33 companies had the value **0** for their rank in the Fortune 500 for the previous year. Given that a rank of zero doesn't exist, we might conclude that these companies didn't have a rank at all for the previous year. It would make more sense for us to replace these values with a null value to more clearly indicate that the value is missing. There are a few things we need to be able to do before we can correct this. The first is how to assign values using pandas.\n",
        "\n",
        "When we used NumPy, we learned that the same techniques that we use to select data could be used for assignment. Let's look at an example:\n",
        "\n",
        "\n",
        "```python\n",
        "my_array = np.array([1, 2, 3, 4])\n",
        "\n",
        "# to perform selection\n",
        "print(my_array[0])\n",
        "\n",
        "# to perform assignment\n",
        "my_array[0] = 99\n",
        "```\n",
        "\n",
        "The same is true with pandas. Let's look at this example:\n",
        "\n",
        "```python\n",
        ">>> top5_rank_revenue = f500[[\"rank\", \"revenues\"]].head()\n",
        "\n",
        ">>> print(top5_rank_revenue)\n",
        "                              rank  revenues\n",
        "    Walmart                      1    485873\n",
        "    State Grid                   2    315199\n",
        "    Sinopec Group                3    267518\n",
        "    China National Petroleum     4    262573\n",
        "    Toyota Motor                 5    254694\n",
        "\n",
        ">>> top5_rank_revenue[\"revenues\"] = 0\n",
        "\n",
        ">>> print(top5_rank_revenue)\n",
        "                              rank  revenues\n",
        "    Walmart                      1         0\n",
        "    State Grid                   2         0\n",
        "    Sinopec Group                3         0\n",
        "    China National Petroleum     4         0\n",
        "    Toyota Motor                 5         0\n",
        "    \n",
        "```\n",
        "\n",
        "\n",
        "When we selected a whole column by label and use assignment, we assigned the value to every item in that column.\n",
        "\n",
        "By providing labels for both axes, we can assign to a single value within our dataframe.\n",
        "\n",
        "```python\n",
        ">>> top5_rank_revenue.loc[\"Sinopec Group\", \"revenues\"] = 999\n",
        "\n",
        ">>> print(top5_rank_revenue)\n",
        "                              rank  revenues\n",
        "    Walmart                      1         0\n",
        "    State Grid                   2         0\n",
        "    Sinopec Group                3       999\n",
        "    China National Petroleum     4         0\n",
        "    Toyota Motor                 5         0\n",
        "```\n",
        "\n",
        "If we assign a value using a index or column label that does not exist, pandas will create a new row or column in our dataframe. Let's add a new column and new row to our **top5_rank_revenue** dataframe:\n",
        "\n",
        "```python\n",
        ">>> top5_rank_revenue[\"year_founded\"] = 0\n",
        "\n",
        ">>> print(top5_rank_revenue)\n",
        "\n",
        "                              rank  revenues  year_founded\n",
        "    Walmart                      1         0             0\n",
        "    State Grid                   2         0             0\n",
        "    Sinopec Group                3       999             0\n",
        "    China National Petroleum     4         0             0\n",
        "    Toyota Motor                 5         0             0\n",
        "\n",
        ">>> top5_rank_revenue.loc[\"My New Company\"] = 555\n",
        "\n",
        ">>> print(top5_rank_revenue)\n",
        "\n",
        "                              rank  revenues  year_founded\n",
        "    Walmart                      1         0             0\n",
        "    State Grid                   2         0             0\n",
        "    Sinopec Group                3       999             0\n",
        "    China National Petroleum     4         0             0\n",
        "    Toyota Motor                 5         0             0\n",
        "    My New Company             555       555           555\n",
        "```\n",
        "\n",
        "\n",
        "There is one exception to be aware of: You **can't** create a new row/column by attempting to use the dot accessor shortcut with a label that does not exist.\n",
        "\n",
        "Let's practice assigning values and adding new columns using our full Fortune 500 dataframe:\n",
        "\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "- Add a new column, **revenues_b** to the **f500** dataframe by using vectorized division to divide the values in the existing **revenues** column by 1000 (converting them from millions to billions).\n",
        "- The company **'Dow Chemical'** have named a new CEO. Update the value where the index label is **Dow Chemical** and for the **ceo** column to **Jim Fitterling**."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fbvJBQzLTuNX",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "X0sKBpdxVMM_"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.10 Using Boolean Indexing with pandas Objects\n"
      ]
    },
    {
      "metadata": {
        "id": "TjV4t1KJ85GU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now that we know how assign values in pandas, we're one step closer to being able to correct the values in the **previous_rank** column that are **0**. If we knew the name of every single row label where this case was true, we could do this manually by using a list of labels when we performed our assignment.\n",
        "\n",
        "While it's helpful to be able to replace specific values in rows where we know the row label ahead of time, this is cumbersome when we want to do this for all rows that meet the same criteria. Another option would be to use a loop, but this would be slower and would lose the benefits of vectorization that pandas gives us. Instead, we can use **boolean indexing**.\n",
        "\n",
        "Just like NumPy, pandas allows us to use boolean indexing to select items based on their value, which will make our task a lot easier. Let's refresh our memory of how boolean indexing is used for selection, and learn how boolean indexing works in pandas.\n",
        "\n",
        "In NumPy, boolean arrays are created by performing a vectorized boolean comparison on a NumPy ndarray. In pandas this works almost identically, however the resulting boolean object will be either a series or a dataframe, depending on the object on which the boolean comparison was performed. Let's look an example of performing a boolean comparison on a series vs a dataframe:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1BJNbnwxzO7TBjbYhFJppw1o93Tnn7xMU\">\n",
        "\n",
        "\n",
        "It's much less common to use a boolean dataframe than a boolean series in pandas. You almost always want to use the results of a comparison on one column from dataframe (a series object) to select data in the main dataframe, or a selection of the main dataframe.\n",
        "\n",
        "Let's look at two examples of how that works in diagram form. For our example, we'll be working with this dataframe of people and their favorite numbers:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1FqhK-Kfr7u7JDeAbfEFxn3_0nONlIpp1\">\n",
        "\n",
        "Let's check which people have a favorite number of 8. We perform a vectorized boolean operation that produces a boolean series:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1OgQSNM8KwzI5Mr3UJ4Y-89tXdc9t6Ybg\">\n",
        "\n",
        "\n",
        "We can use that series to index the whole dataframe, leaving us the rows that correspond only to people whose favorite number is 8.\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1WeDutjUzaV2RqdHgJkSVWQNPOguqskak\">\n",
        "\n",
        "Note that we didn't used **loc[]**. This is because boolean arrays use the same shortcut as slices to select along the index axis. \n",
        "\n",
        "\n",
        "Now let's look at an example of using boolean indexing with our Fortune 500 dataset. We want find out which are the 5 most common countries for companies belonging to the **'Motor Vehicles and Parts'** industry.\n",
        "\n",
        "We start by making a boolean series that shows us which rows from our dataframe have the value of **Motor Vehicles and Parts** for the **industry** column. We'll then print the first five items of our boolean series so we can see it in action:\n",
        "\n",
        "\n",
        "```python\n",
        ">>> motor_bool = f500[\"industry\"] == \"Motor Vehicles and Parts\"\n",
        "\n",
        ">>> print(motor_bool.head())\n",
        "\n",
        "    Walmart                     False\n",
        "    State Grid                  False\n",
        "    Sinopec Group               False\n",
        "    China National Petroleum    False\n",
        "    Toyota Motor                 True\n",
        "    Name: industry, dtype: bool\n",
        "```\n",
        "\n",
        "\n",
        "Notice that like our examples in the diagrams above, the index labels are retained in our boolean series. Next, we use that boolean series to select only the rows that have **True** for our boolean index, and just the **country** column, and then print the first 5 items to check the values:\n",
        "\n",
        "```python\n",
        ">>> motor_countries = f500.loc[motor_bool, \"country\"]\n",
        "\n",
        ">>> print(motor_countries.head())\n",
        "\n",
        "    Toyota Motor        Japan\n",
        "    Volkswagen        Germany\n",
        "    Daimler           Germany\n",
        "    General Motors        USA\n",
        "    Ford Motor            USA\n",
        "    Name: country, dtype: object\n",
        "```\n",
        "\n",
        "\n",
        "Lastly, we can use the **value_counts()** method for the **motor_countries** series, chained to the **head()** method to produce a series of the top 5 countries for the 'Motor Vehicles and Parts' industry:\n",
        "\n",
        "```python\n",
        ">>> top5_motor_countries = motor_countries.value_counts().head()\n",
        "\n",
        ">>> print(top5_motor_countries)\n",
        "\n",
        "    Japan          10\n",
        "    China           7\n",
        "    Germany         6\n",
        "    France          3\n",
        "    South Korea     3\n",
        "    Name: country, dtype: int64\n",
        "```\n",
        "\n",
        "Let's practice using boolean indexing in pandas to identify the five highest ranked companies from South Korea. Remember, we observed earlier that the **f500** dataframe is already sorted by rank, so we won't need to perfom any extra sorting.\n",
        "\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "- Create a boolean series, **kr_bool**, that compares whether the values in the **country** column from the **f500** dataframe are equal to **\"South Korea\"**\n",
        "- Use that boolean series to index the full **f500** dataframe, assigning just the first five rows to **top_5_kr.**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bx5OBhlIVtDr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wF256cCCnWVa"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.11 Using Boolean Arrays to Assign Values\n"
      ]
    },
    {
      "metadata": {
        "id": "mii8Gwsi87VY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "We now have all the knowledge we need to fix the 0 values in the **previous_rank** column:\n",
        "\n",
        "- perform assignment in pandas\n",
        "- use boolean indexing in pandas\n",
        "\n",
        "Let's look at an example of how we combine these two operations together. For our example, we'll want to change the **'Motor Vehicles & Parts'** values in the **sector** column to **'Motor Vehicles and Parts'** – i.e. we will change the ampersand **(&)** to **and**.\n",
        "\n",
        "First, we create a boolean series by comparing the values in the sector column to **'Motor Vehicles & Parts'**.\n",
        "\n",
        "```python\n",
        "ampersand_bool = f500[\"sector\"] == \"Motor Vehicles & Parts\"\n",
        "```\n",
        "\n",
        "Next, we use that boolean series and the string **\"sector\"** to perform the assignment.\n",
        "\n",
        "```python\n",
        "f500.loc[ampersand_bool,\"sector\"] = \"Motor Vehicles and Parts\"\n",
        "```\n",
        "\n",
        "Just like we saw in the NumPy mission earlier in this course, we can remove the intermediate step of creating a boolean series, and combine everything into one line. This is the most common way to write pandas code to perform assignment using boolean arrays:\n",
        "\n",
        "```python\n",
        "f500.loc[f500[\"sector\"] == \"Motor Vehicles & Parts\",\"sector\"] = \"Motor Vehicles and Parts\"\n",
        "```\n",
        "\n",
        "Now we can follow this pattern to replace the values in the **previous_rank** column. We'll replace these values with **np.nan**, which is used in pandas, just as it is in numpy, to represent values that can't be represented numerically, most commonly missing values.\n",
        "\n",
        "To make comparing the values in this column before and after our operation easier, we've added the following line of code to the cell below:\n",
        "\n",
        "```python\n",
        "prev_rank_before = f500[\"previous_rank\"].value_counts(dropna=False).head()\n",
        "```\n",
        "\n",
        "This uses **Series.value_counts()** and **Series.head()** to display the 5 most common values in the **previous_rank** column, but adds an additional **dropna=False** parameter, which stops the **Series.value_counts()** method from excluding null values when it makes its calculation, as shown in the [Series.value_counts() documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html#pandas.Series.value_counts).\n",
        "\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "- Use boolean indexing to update values in the **previous_rank** column of the **f500** dataframe:\n",
        "  - Where previous there was a value of 0, there should now be a value of **np.nan**.\n",
        "  - It is up to you whether you assign the boolean series to its own variable first, or whether you complete the operation in one line.\n",
        "- Create a new pandas series, **prev_rank_after**, using the same syntax that was used to create the **prev_rank_before series.**\n",
        "- After you have run your code, use the variable inspector to compare **prev_rank_before** and **prev_rank_after.**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aAKjY4M6ozNI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "prev_rank_before = f500[\"previous_rank\"].value_counts(dropna=False).head()\n",
        "\n",
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wjtwE9KKrF5Z"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.12 Challenge: Top Performers by Country\n"
      ]
    },
    {
      "metadata": {
        "id": "LJCxlf5O9NvB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "You may have noticed that after we assigned NaN values the previous_rank column changed dtype. Let's take a closer look:\n",
        "\n",
        "```python\n",
        ">>> print(prev_rank_before)\n",
        "\n",
        "    0      33\n",
        "    159     1\n",
        "    147     1\n",
        "    148     1\n",
        "    149     1\n",
        "\n",
        ">>> print(prev_rank_after)\n",
        "\n",
        "    NaN      33\n",
        "    471.0     1\n",
        "    234.0     1\n",
        "    125.0     1\n",
        "    166.0     1\n",
        "```\n",
        "\n",
        "The index of the series that **Series.value_counts()** produces is now showing us floats like 471.0 instead of the integers from before. The reason behind this is that pandas uses the NumPy integer dtype, which does not support NaN values. Pandas inherits this behavior, and in instances where you try and assign a NaN value to an integer column, pandas will silently convert that column to a float dtype. If you're interested in finding out more about this, [there is a specific section on integer NaN values in the pandas documentation](http://pandas.pydata.org/pandas-docs/stable/gotchas.html#nan-integer-na-values-and-na-type-promotions).\n",
        "\n",
        "We'll finish this mission with a challenge. In this challenge, we'll calculate a specific statistic or attribute of each of the three most common countries from our f500 dataframe. We've identified the three most common countries using the code below:\n",
        "\n",
        "```python\n",
        ">>> top_3_countries = f500[\"country\"].value_counts().head(3)\n",
        "\n",
        ">>> print(top_3_countries)\n",
        "\n",
        "USA      132\n",
        "China    109\n",
        "Japan     51\n",
        "Name: country, dtype: int64\n",
        "```\n",
        "\n",
        "Don't be discouraged if this takes a few attempts to get right– working with data is an iterative process!\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "1. Create a series, **cities_usa**, containing counts of the five most common Headquarter Location cities for companies headquartered in the USA.\n",
        "2. Create a series, **sector_china**, containing counts of the three most common sectors for companies headquartered in the China.\n",
        "3. Create float object, **mean_employees_japan**, containing the mean average number of employees for companies headquartered in Japan"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3Z8ouPzEsktk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ITsazgBWsuJT"
      },
      "cell_type": "markdown",
      "source": [
        "In this lesson, we learned:\n",
        "\n",
        "- How pandas can be combined to make working with data easier\n",
        "- About the two core pandas types: series and dataframes\n",
        "- How to select data from pandas objects using axis labels\n",
        "- How to select data from pandas objects using boolean arrays\n",
        "- How to assign data using labels and boolean arrays\n",
        "- How to create new rows and columns in pandas\n",
        "- Many new methods to make data analysis easier in pandas."
      ]
    }
  ]
}